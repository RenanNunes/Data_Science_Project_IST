{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 - Decision Tree\n",
    "The model that will be analyzed this time is Decision Trees.\n",
    "\n",
    "There are some parameters that influentiate the model, therefore the tests involve changing these parameters to see which returns the best result. The values will be:\n",
    "\n",
    "* The minimum number of samples required to be at a leaf node (in percentage): [.05, .025, .01, .0075, .005, .0025, .001]\n",
    "* The maximum depth of the tree: [5, 10, 25, 50]\n",
    "* The function to measure the quality of a split: ['entropy', 'gini']\n",
    "\n",
    "**To do(?)-(Obs: the data preparation (feature selection, data imputation, normalization) should be done for training dataset without the training (and for each fold in a cross validation) - needs to care about to get a 20)  \n",
    "Always use the same seed to create the folds/split to compare the classifiers fairly (with all using the same data)  \n",
    "The professor doesn't like the graph with multiple lines varying nr estimators and max depth, he said that is better to fix one and vary the other, for example: fix one small and one big max depth and them vary the nr estimators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphFunctions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9fcc0b05acdb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodelAnalyzesFunctions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0manalyzes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\POLI\\IST1\\CD\\Ciencia_de_Dados-IST\\utils\\modelAnalyzesFunctions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgraphFunctions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mnaive_bayes_analyzes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrskf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle_complement\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'- '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'graphFunctions'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import sklearn.metrics as metrics\n",
    "import itertools\n",
    "from utils import modelAnalyzesFunctions as analyzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_7: pd.DataFrame = pd.read_csv('../datasets/pd_data_preparation_7.csv', sep=',', decimal='.', index_col='id')\n",
    "y_7: np.ndarray = data_7.pop('class').values\n",
    "X_7: np.ndarray = data_7.values\n",
    "labels_7 = pd.unique(y_7)\n",
    "\n",
    "data_8: pd.DataFrame = pd.read_csv('../datasets/pd_data_preparation.csv', sep=',', decimal='.', index_col='id')\n",
    "y_8: np.ndarray = data_8.pop('class').values\n",
    "X_8: np.ndarray = data_8.values\n",
    "labels_8 = pd.unique(y_8)\n",
    "\n",
    "data_9: pd.DataFrame = pd.read_csv('../datasets/pd_data_preparation_9.csv', sep=',', decimal='.', index_col='id')\n",
    "y_9: np.ndarray = data_9.pop('class').values\n",
    "X_9: np.ndarray = data_9.values\n",
    "labels_9 = pd.unique(y_9)\n",
    "\n",
    "data_8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 4\n",
    "n_repeats = 3\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits, n_repeats, random_state=42)\n",
    "\n",
    "min_samples_leaf = [.05, .025, .01, .0075, .005, .0025, .001]\n",
    "max_depths = [5, 10, 25, 50]\n",
    "criteria = ['entropy', 'gini']\n",
    "\n",
    "accuracy, sensitivity, decision_trees = analyzes.decision_tree_analyzes(X_8, y_8, min_samples_leaf, max_depths, criteria, rskf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in criteria:\n",
    "    max_acc, max_sens = analyzes.get_max_accuracy_sensitivity_data(accuracy, sensitivity, max_depths, min_samples_leaf, c)\n",
    "    \n",
    "    print()\n",
    "    print(c, '- max accuracy:')\n",
    "    print('Accuracy:', max_acc['acc'])\n",
    "    print('Sensitivity:', max_acc['sens'])\n",
    "    print('max_depth:', max_acc['max_depth'])\n",
    "    print('min_samples_leaf:', max_acc['min_sample_leaf'])\n",
    "    print()\n",
    "    print(c, '- max sensitivity:')\n",
    "    print('Accuracy:', max_sens['acc'])\n",
    "    print('Sensitivity:', max_sens['sens'])\n",
    "    print('max_depth:', max_sens['max_depth'])\n",
    "    print('min_samples_leaf:', max_sens['min_sample_leaf'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the gini criteria happened to be best in this dataset. Comparing with other models, it's still worse than KNN's accuracy (one of them got 0.8528 accuracy), although the sensitivity is better (0.8032 > 0.7252)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_7, sensitivity_7, decision_trees_7 = analyzes.decision_tree_analyzes(X_7, y_7, min_samples_leaf, max_depths, criteria, rskf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in criteria:\n",
    "    max_acc, max_sens = analyzes.get_max_accuracy_sensitivity_data(accuracy_7, sensitivity_7, max_depths, min_samples_leaf, c)\n",
    "    \n",
    "    print()\n",
    "    print(c, '- max accuracy:')\n",
    "    print('Accuracy:', max_acc['acc'])\n",
    "    print('Sensitivity:', max_acc['sens'])\n",
    "    print('max_depth:', max_acc['max_depth'])\n",
    "    print('min_samples_leaf:', max_acc['min_sample_leaf'])\n",
    "    print()\n",
    "    print(c, '- max sensitivity:')\n",
    "    print('Accuracy:', max_sens['acc'])\n",
    "    print('Sensitivity:', max_sens['sens'])\n",
    "    print('max_depth:', max_sens['max_depth'])\n",
    "    print('min_samples_leaf:', max_sens['min_sample_leaf'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_9, sensitivity_9, decision_trees_9 = analyzes.decision_tree_analyzes(X_9, y_9, min_samples_leaf, max_depths, criteria, rskf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in criteria:\n",
    "    max_acc, max_sens = analyzes.get_max_accuracy_sensitivity_data(accuracy_9, sensitivity_9, max_depths, min_samples_leaf, c)\n",
    "    \n",
    "    print()\n",
    "    print(c, '- max accuracy:')\n",
    "    print('Accuracy:', max_acc['acc'])\n",
    "    print('Sensitivity:', max_acc['sens'])\n",
    "    print('max_depth:', max_acc['max_depth'])\n",
    "    print('min_samples_leaf:', max_acc['min_sample_leaf'])\n",
    "    print()\n",
    "    print(c, '- max sensitivity:')\n",
    "    print('Accuracy:', max_sens['acc'])\n",
    "    print('Sensitivity:', max_sens['sens'])\n",
    "    print('max_depth:', max_sens['max_depth'])\n",
    "    print('min_samples_leaf:', max_sens['min_sample_leaf'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the entropy criteria ended up with a better accuracy and senstivity than the 0.8's dataset, showing how well decision trees can handle high dimensionality.\n",
    "\n",
    "To ilustrate the decision tree, one example will be plotted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dot_data = export_graphviz(decision_trees_9['entropy'][25][10], out_file='dtree.dot', filled=True, rounded=True, special_characters=True)  \n",
    "# Convert to png\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'dtree.dot', '-o', 'dtree.png', '-Gdpi=600'])\n",
    "\n",
    "plt.figure(figsize = (30, 40))\n",
    "plt.imshow(plt.imread('dtree.png'))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
